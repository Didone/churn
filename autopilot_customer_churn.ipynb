{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction with Amazon SageMaker Autopilot\n",
    "\n",
    "> Based on [AWS labs](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/autopilot/autopilot_customer_churn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Amazon SageMaker Autopilot is an automated machine learning (commonly referred to as AutoML) solution for tabular datasets. You can use SageMaker Autopilot in different ways: on autopilot (hence the name) or with human guidance, without code through SageMaker Studio, or using the AWS SDKs. This notebook, as a first glimpse, will use the AWS SDKs to simply create and deploy a machine learning model.\n",
    "\n",
    "Losing customers is costly for any business. Identifying unhappy customers early on gives you a chance to offer them incentives to stay. This notebook describes using machine learning (ML) for the automated identification of unhappy customers, also known as customer churn prediction. ML models rarely give perfect predictions though, so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.\n",
    "\n",
    "We use an example of churn that is familiar to all of us–leaving a mobile phone operator. Seems like I can always find fault with my provider du jour! And if my provider knows that I’m thinking of leaving, it can offer timely incentives–I can always use a phone upgrade or perhaps have a new feature activated–and I might just stick around. Incentives are often much more cost effective than losing and reacquiring a customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Let's start by specifying:\n",
    "\n",
    "+ The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "+ The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "# You can modify the following to use a bucket of your choosing\n",
    "bucket = os.environ['DORA_BUCKET']\n",
    "prefix = 'workspaces/didone/notebooks/churn/sagemaker/autopilot-churn'\n",
    "role = \"arn:aws:iam::229343956935:role/DoraSageMaker\"\n",
    "# This is the client we will use to interact with SageMaker AutoPilot\n",
    "sm = boto3.Session().client(service_name='sagemaker',region_name=os.environ['AWS_REGION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Mobile operators have historical records on which customers ultimately ended up churning and which continued using the service. We can use this historical information to construct an ML model of one mobile operator’s churn using a process called training. After training the model, we can pass the profile information of an arbitrary customer (the same profile information that we used to train the model) to the model, and have the model predict whether this customer is going to churn. Of course, we expect the model to make mistakes–after all, predicting the future is tricky business! But I’ll also show how to deal with prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CEP: string, ESTADO: string, GENERO: string, DDD: string, CELULAR: string, IDADE: double, IDADE_CONTA: double, CREDITO: float, DEBITO: float, T_SERVICOS: float, T_EDUCACAO: float, T_RESTAURANTE: float, T_TRANSPORTE: float, T_LAZER: float, T_SUPERMERCADO: float, T_OUTROS: float, CHURN: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql --out churn_df\n",
    "SELECT * \n",
    "  FROM CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CEP</th>\n",
       "      <th>ESTADO</th>\n",
       "      <th>GENERO</th>\n",
       "      <th>DDD</th>\n",
       "      <th>CELULAR</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>IDADE_CONTA</th>\n",
       "      <th>CREDITO</th>\n",
       "      <th>DEBITO</th>\n",
       "      <th>T_SERVICOS</th>\n",
       "      <th>T_EDUCACAO</th>\n",
       "      <th>T_RESTAURANTE</th>\n",
       "      <th>T_TRANSPORTE</th>\n",
       "      <th>T_LAZER</th>\n",
       "      <th>T_SUPERMERCADO</th>\n",
       "      <th>T_OUTROS</th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55677</td>\n",
       "      <td>DF</td>\n",
       "      <td>male</td>\n",
       "      <td>47</td>\n",
       "      <td>50211417</td>\n",
       "      <td>53.775342</td>\n",
       "      <td>2.290411</td>\n",
       "      <td>700.840027</td>\n",
       "      <td>1544.959961</td>\n",
       "      <td>721.349976</td>\n",
       "      <td>413.160004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1111.290039</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58832</td>\n",
       "      <td>MT</td>\n",
       "      <td>male</td>\n",
       "      <td>99</td>\n",
       "      <td>45970533</td>\n",
       "      <td>28.068493</td>\n",
       "      <td>0.841096</td>\n",
       "      <td>62.759998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.759998</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15749</td>\n",
       "      <td>TO</td>\n",
       "      <td>female</td>\n",
       "      <td>93</td>\n",
       "      <td>94534932</td>\n",
       "      <td>42.073973</td>\n",
       "      <td>10.728767</td>\n",
       "      <td>1443.819946</td>\n",
       "      <td>444.799988</td>\n",
       "      <td>247.649994</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>599.580017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.690002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>938.799988</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14347</td>\n",
       "      <td>BA</td>\n",
       "      <td>female</td>\n",
       "      <td>55</td>\n",
       "      <td>51339848</td>\n",
       "      <td>38.087671</td>\n",
       "      <td>6.128767</td>\n",
       "      <td>622.849976</td>\n",
       "      <td>108.800003</td>\n",
       "      <td>65.919998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>622.849976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.880001</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38421</td>\n",
       "      <td>AP</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>75545166</td>\n",
       "      <td>58.624658</td>\n",
       "      <td>13.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>374.040009</td>\n",
       "      <td>374.040009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>19633</td>\n",
       "      <td>AC</td>\n",
       "      <td>male</td>\n",
       "      <td>78</td>\n",
       "      <td>07813780</td>\n",
       "      <td>34.953425</td>\n",
       "      <td>4.191781</td>\n",
       "      <td>798.159973</td>\n",
       "      <td>806.849976</td>\n",
       "      <td>68.110001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.330002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>558.450012</td>\n",
       "      <td>175.300003</td>\n",
       "      <td>754.820007</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>37529</td>\n",
       "      <td>AP</td>\n",
       "      <td>male</td>\n",
       "      <td>10</td>\n",
       "      <td>09231334</td>\n",
       "      <td>52.572603</td>\n",
       "      <td>11.726027</td>\n",
       "      <td>483.510010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>483.510010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>10835</td>\n",
       "      <td>RO</td>\n",
       "      <td>female</td>\n",
       "      <td>44</td>\n",
       "      <td>02921384</td>\n",
       "      <td>72.263014</td>\n",
       "      <td>17.213699</td>\n",
       "      <td>1309.709961</td>\n",
       "      <td>864.960022</td>\n",
       "      <td>50.480000</td>\n",
       "      <td>634.369995</td>\n",
       "      <td>891.609985</td>\n",
       "      <td>302.429993</td>\n",
       "      <td>65.190002</td>\n",
       "      <td>230.589996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>89047</td>\n",
       "      <td>BA</td>\n",
       "      <td>male</td>\n",
       "      <td>95</td>\n",
       "      <td>86082525</td>\n",
       "      <td>48.956164</td>\n",
       "      <td>17.975342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.599998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.599998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>74183</td>\n",
       "      <td>ES</td>\n",
       "      <td>female</td>\n",
       "      <td>44</td>\n",
       "      <td>91899317</td>\n",
       "      <td>35.287671</td>\n",
       "      <td>17.353425</td>\n",
       "      <td>2043.489990</td>\n",
       "      <td>1874.719971</td>\n",
       "      <td>445.570007</td>\n",
       "      <td>871.780029</td>\n",
       "      <td>1047.119995</td>\n",
       "      <td>684.919983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>744.229980</td>\n",
       "      <td>124.589996</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CEP ESTADO  GENERO DDD   CELULAR      IDADE  IDADE_CONTA      CREDITO  \\\n",
       "0    55677     DF    male  47  50211417  53.775342     2.290411   700.840027   \n",
       "1    58832     MT    male  99  45970533  28.068493     0.841096    62.759998   \n",
       "2    15749     TO  female  93  94534932  42.073973    10.728767  1443.819946   \n",
       "3    14347     BA  female  55  51339848  38.087671     6.128767   622.849976   \n",
       "4    38421     AP  female  25  75545166  58.624658    13.027397     0.000000   \n",
       "..     ...    ...     ...  ..       ...        ...          ...          ...   \n",
       "918  19633     AC    male  78  07813780  34.953425     4.191781   798.159973   \n",
       "919  37529     AP    male  10  09231334  52.572603    11.726027   483.510010   \n",
       "920  10835     RO  female  44  02921384  72.263014    17.213699  1309.709961   \n",
       "921  89047     BA    male  95  86082525  48.956164    17.975342     0.000000   \n",
       "922  74183     ES  female  44  91899317  35.287671    17.353425  2043.489990   \n",
       "\n",
       "          DEBITO  T_SERVICOS  T_EDUCACAO  T_RESTAURANTE  T_TRANSPORTE  \\\n",
       "0    1544.959961  721.349976  413.160004       0.000000      0.000000   \n",
       "1       0.000000    0.000000    0.000000       0.000000      0.000000   \n",
       "2     444.799988  247.649994    0.900000     599.580017      0.000000   \n",
       "3     108.800003   65.919998    0.000000     622.849976      0.000000   \n",
       "4     374.040009  374.040009    0.000000       0.000000      0.000000   \n",
       "..           ...         ...         ...            ...           ...   \n",
       "918   806.849976   68.110001    0.000000      48.330002      0.000000   \n",
       "919     0.000000  483.510010    0.000000       0.000000      0.000000   \n",
       "920   864.960022   50.480000  634.369995     891.609985    302.429993   \n",
       "921    80.599998    0.000000    0.000000       0.000000     80.599998   \n",
       "922  1874.719971  445.570007  871.780029    1047.119995    684.919983   \n",
       "\n",
       "        T_LAZER  T_SUPERMERCADO     T_OUTROS   CHURN  \n",
       "0      0.000000        0.000000  1111.290039  False.  \n",
       "1      0.000000        0.000000    62.759998  False.  \n",
       "2    101.690002        0.000000   938.799988  False.  \n",
       "3      0.000000        0.000000    42.880001  False.  \n",
       "4      0.000000        0.000000     0.000000  False.  \n",
       "..          ...             ...          ...     ...  \n",
       "918  558.450012      175.300003   754.820007  False.  \n",
       "919    0.000000        0.000000     0.000000  False.  \n",
       "920   65.190002      230.589996     0.000000   True.  \n",
       "921    0.000000        0.000000     0.000000   True.  \n",
       "922    0.000000      744.229980   124.589996   True.  \n",
       "\n",
       "[923 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = churn_df.toPandas()\n",
    "pd.set_option('display.max_columns', 500)\n",
    "churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reserve some data for calling inference on the model\n",
    "\n",
    "Divide the data into training and testing splits. The training split is used by SageMaker Autopilot. The testing split is reserved to perform inference using the suggested model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = churn.sample(frac=0.8,random_state=200)\n",
    "test_data = churn.drop(train_data.index)\n",
    "test_data_no_target = test_data.drop(columns=['CHURN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data uploaded to: s3://autonomous-sandbox/workspaces/didone/notebooks/churn/sagemaker/autopilot-churn/train/train_data.csv\n",
      "Test data uploaded to: s3://autonomous-sandbox/workspaces/didone/notebooks/churn/sagemaker/autopilot-churn/test/test_data.csv\n"
     ]
    }
   ],
   "source": [
    "train_file = 'train_data.csv';\n",
    "train_data.to_csv(train_file, index=False, header=True)\n",
    "train_data_s3_path = session.upload_data(bucket=os.environ['DORA_BUCKET'], path=train_file, key_prefix=prefix + \"/train\")\n",
    "print('Train data uploaded to: ' + train_data_s3_path)\n",
    "\n",
    "test_file = 'test_data.csv';\n",
    "test_data_no_target.to_csv(test_file, index=False, header=False)\n",
    "test_data_s3_path = session.upload_data(bucket=os.environ['DORA_BUCKET'], path=test_file, key_prefix=prefix + \"/test\")\n",
    "print('Test data uploaded to: ' + test_data_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the SageMaker Autopilot Job\n",
    "\n",
    "After uploading the dataset to Amazon S3, you can invoke Autopilot to find the best ML pipeline to train a model on this dataset.\n",
    "\n",
    "The required inputs for invoking a Autopilot job are:\n",
    "\n",
    "+ Amazon S3 location for input dataset and for all output artifacts\n",
    "+ Name of the column of the dataset you want to predict (Churn? in this case)\n",
    "+ An IAM role\n",
    "\n",
    "Currently Autopilot supports only tabular datasets in CSV format. Either all files should have a header row, or the first file of the dataset, when sorted in alphabetical/lexical order by name, is expected to have a header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_config = [{\n",
    "      'DataSource': {\n",
    "        'S3DataSource': {\n",
    "          'S3DataType': 'S3Prefix',\n",
    "          'S3Uri': 's3://{}/{}/train'.format(bucket,prefix)\n",
    "        }\n",
    "      },\n",
    "      'TargetAttributeName': 'CHURN'\n",
    "    }\n",
    "  ]\n",
    "\n",
    "output_data_config = {\n",
    "    'S3OutputPath': 's3://{}/{}/output'.format(bucket,prefix)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify the type of problem you want to solve with your dataset (Regression, MulticlassClassification, BinaryClassification). In case you are not sure, SageMaker Autopilot will infer the problem type based on statistics of the target column (the column you want to predict).\n",
    "\n",
    "Because the target attribute, Churn?, is binary, our model will be performing binary prediction, also known as binary classification. In this example we will let AutoPilot infer the type of problem for us.\n",
    "\n",
    "You have the option to limit the running time of a SageMaker Autopilot job by providing either the maximum number of pipeline evaluations or candidates (one pipeline evaluation is called a Candidate because it generates a candidate model) or providing the total time allocated for the overall Autopilot job. Under default settings, this job takes about four hours to run. This varies between runs because of the nature of the exploratory process Autopilot uses to find optimal training parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the SageMaker Autopilot Job\n",
    "\n",
    "You can now launch the Autopilot job by calling the create_auto_ml_job API. We limit the number of candidates to 20 so that the job finishes in a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLJobName: automl-churn-15-14-48-30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AutoMLJobArn': 'arn:aws:sagemaker:us-east-1:229343956935:automl-job/automl-churn-15-14-48-30',\n",
       " 'ResponseMetadata': {'RequestId': '67b36105-1278-47af-8dbc-432247ac0b5a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '67b36105-1278-47af-8dbc-432247ac0b5a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '95',\n",
       "   'date': 'Wed, 15 Apr 2020 14:48:30 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "timestamp_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "auto_ml_job_name = 'automl-churn-' + timestamp_suffix\n",
    "print('AutoMLJobName: ' + auto_ml_job_name)\n",
    "sm.create_auto_ml_job(AutoMLJobName=auto_ml_job_name,\n",
    "                      InputDataConfig=input_data_config,\n",
    "                      OutputDataConfig=output_data_config,\n",
    "                      AutoMLJobConfig={'CompletionCriteria':\n",
    "                                       {'MaxCandidates': 20}\n",
    "                                      },\n",
    "                      RoleArn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking SageMaker Autopilot job progress\n",
    "\n",
    "SageMaker Autopilot job consists of the following high-level steps :\n",
    "\n",
    "+ Analyzing Data, where the dataset is analyzed and Autopilot comes up with a list of ML pipelines that should be tried out on the dataset. The dataset is also split into train and validation sets.\n",
    "+ Feature Engineering, where Autopilot performs feature transformation on individual features of the dataset as well as at an aggregate level.\n",
    "+ Model Tuning, where the top performing pipeline is selected along with the optimal hyperparameters for the training algorithm (the last stage of the pipeline).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus - Secondary Status\n",
      "------------------------------\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "Failed - Failed\n"
     ]
    }
   ],
   "source": [
    "print ('JobStatus - Secondary Status')\n",
    "print('------------------------------')\n",
    "\n",
    "describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "    job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "    print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Now use the describe_auto_ml_job API to look up the best candidate selected by the SageMaker Autopilot job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BestCandidate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ff93b5ad670f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_candidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_auto_ml_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoMLJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_ml_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BestCandidate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_candidate_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CandidateName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_candidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CandidateName: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbest_candidate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BestCandidate'"
     ]
    }
   ],
   "source": [
    "best_candidate = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['BestCandidate']\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "print(best_candidate)\n",
    "print('\\n')\n",
    "print(\"CandidateName: \" + best_candidate_name)\n",
    "print(\"FinalAutoMLJobObjectiveMetricName: \" + best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\n",
    "print(\"FinalAutoMLJobObjectiveMetricValue: \" + str(best_candidate['FinalAutoMLJobObjectiveMetric']['Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to some randomness in the algorithms involved, different runs will provide slightly different results, but accuracy will be around or above $93\\%$, which is a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host\n",
    "\n",
    "Now that we've trained the algorithm, let's create a model and deploy it to a hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "model_name = best_candidate_name + timestamp_suffix + \"-model\"\n",
    "model_arn = sm.create_model(Containers=best_candidate['InferenceContainers'],\n",
    "                            ModelName=model_name,\n",
    "                            ExecutionRoleArn=role)\n",
    "\n",
    "epc_name = best_candidate_name + timestamp_suffix + \"-epc\"\n",
    "ep_config = sm.create_endpoint_config(EndpointConfigName = epc_name,\n",
    "                                      ProductionVariants=[{'InstanceType': 'ml.m5.2xlarge',\n",
    "                                                           'InitialInstanceCount': 1,\n",
    "                                                           'ModelName': model_name,\n",
    "                                                           'VariantName': 'main'}])\n",
    "\n",
    "ep_name = best_candidate_name + timestamp_suffix + \"-ep\"\n",
    "create_endpoint_response = sm.create_endpoint(EndpointName=ep_name,\n",
    "                                              EndpointConfigName=epc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.get_waiter('endpoint_in_service').wait(EndpointName=ep_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Now that we have a hosted endpoint running, we can make real-time predictions from our model very easily, simply by making an http POST request. But first, we'll need to setup serializers and deserializers for passing our test_data NumPy arrays to the model behind the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=ep_name,\n",
    "    sagemaker_session=session,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_CSV)\n",
    "\n",
    "# Remove the target column from the test data\n",
    "test_data_inference = test_data.drop('Churn?', axis=1)\n",
    "\n",
    "# Obtain predictions from SageMaker endpoint\n",
    "prediction = predictor.predict(test_data_inference.to_csv(sep=',', header=False, index=False)).decode('utf-8')\n",
    "\n",
    "# Load prediction in pandas and compare to ground truth\n",
    "prediction_df = pd.read_csv(StringIO(prediction), header=None)\n",
    "accuracy = (test_data.reset_index()['Churn?'] == prediction_df[0]).sum() / len(test_data_inference)\n",
    "print('Accuracy: {}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "The Autopilot job creates many underlying artifacts such as dataset splits, preprocessing scripts, or preprocessed data, etc. This code, when un-commented, deletes them. This operation deletes all the generated models and the auto-generated notebooks as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=ep_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=epc_name)\n",
    "sm.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
